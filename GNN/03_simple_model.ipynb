{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/periadhityan/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/periadhityan/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n",
      "/Users/periadhityan/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "benign_graphs, benign_labels = dgl.load_graphs(\"benign.bin\")\n",
    "malicious_graphs, malicious_labels = dgl.load_graphs(\"malicious.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = benign_graphs+malicious_graphs\n",
    "labels = torch.cat([benign_labels['labels'], malicious_labels['labels']])\n",
    "\n",
    "dataset = list(zip(graphs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    graphs, labels = zip(*batch)\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    batch_labels = torch.stack(labels)\n",
    "\n",
    "    return batched_graph, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=1, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test, batch_size=1, shuffle=False, collate_fn=custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='mean')\n",
    "        \n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='mean')\n",
    "    \n",
    "    def forward(self, graph, inputs):\n",
    "        \n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "\n",
    "        return h\n",
    "\n",
    "class HeteroClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rgcn = RGCN(in_dim, hidden_dim, hidden_dim, rel_names)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        inputs = {ntype: g.nodes[ntype].data['h'] for ntype in g.ntypes}\n",
    "\n",
    "        h = self.rgcn(g, inputs)\n",
    "\n",
    "        with g.local_scope():\n",
    "            for ntype in g.ntypes:\n",
    "                if ntype in h:\n",
    "                    g.nodes[ntype].data['h'] = h[ntype]\n",
    "                else:\n",
    "                    continue\n",
    "            # Calculate graph representation by average readout.\n",
    "\n",
    "            hg = None\n",
    "\n",
    "            for ntype in g.ntypes:\n",
    "                if hg is None:\n",
    "                    hg = dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "                else:\n",
    "                    hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "                \n",
    "            return self.classify(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rel_names = set()\n",
    "\n",
    "for g in graphs:\n",
    "    unique_rel_names.update(g.etypes)\n",
    "\n",
    "unique_rel_names = sorted(unique_rel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "model = HeteroClassifier(1, 1, 2, unique_rel_names)\n",
    "optimiser = Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for graph, label in train_dataloader:\n",
    "        label = label.long()\n",
    "\n",
    "        logits = model(graph)\n",
    "\n",
    "        loss = loss_fn(logits, label)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataloader)}')\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.metrics import classification_report\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for graph, label in test_dataloader:\n",
    "            logits = model(graph)\n",
    "            preds.append(torch.argmax(logits, dim=1))\n",
    "            labels.append(label)\n",
    "\n",
    "    report = classification_report(labels, preds)\n",
    "    print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GNN, self).__init__()\n",
    "        self.fc = nn.Linear(in_feats, hidden_feats)\n",
    "        self.classify = nn.Linear(hidden_feats, out_feats)\n",
    "\n",
    "    def forward(self, graph):\n",
    "\n",
    "        with graph.local_scope():\n",
    "            graph_feats = 0\n",
    "\n",
    "            for ntype in graph.ntypes:\n",
    "                graph_feats += dgl.mean_nodes(graph, 'h', ntype=ntype)\n",
    "\n",
    "            h = self.fc(graph_feats)\n",
    "            hg = F.relu(h)\n",
    "\n",
    "            return self.classify(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "in_feats = 1\n",
    "hidden_feats = 256\n",
    "out_feats = 2\n",
    "\n",
    "model = GNN(in_feats, hidden_feats, out_feats)\n",
    "optimiser = Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_epochs = 50\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for graph, label in train_dataloader:\n",
    "\n",
    "            logits = model(graph)\n",
    "            loss = loss_fn(logits, label.long())\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataloader)}')\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for graph, label in test_dataloader:\n",
    "\n",
    "            logits = model(graph)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            correct += (preds == label).sum().item()\n",
    "            total += len(label)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
